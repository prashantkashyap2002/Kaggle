{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identification:\n",
    "This is the project from Kaggle's dog-breed-identification competition.\n",
    "The data's are being used here from Kaggle's site provided for this competition. \n",
    "Downloded from \n",
    "https://www.kaggle.com/c/dog-breed-identification/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lib imported successfully\n"
     ]
    }
   ],
   "source": [
    "### Import all relevent lib\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import helper\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from numpy import prod\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "### Dir\n",
    "#LABELS = 'data/labels.csv'\n",
    "#DATA_FILE = 'data/data.csv'\n",
    "#TRAIN_IMAGE_DIR = 'data/train/'\n",
    "#TEST_IMAGE_DIR = 'data/test/'\n",
    "#IMAGE_SIZE = 32,32\n",
    "CHANNEL = 3\n",
    "SIZE = 64\n",
    "#PIXEL_DEPTH = 255\n",
    "labels_count = 120\n",
    "# Model save path\n",
    "save_model_path = './dog_breed_recognition'\n",
    "\n",
    "# Change if have a memory restrictions\n",
    "batch_size = 2048\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 3\n",
    "keep_probability = 1\n",
    "\n",
    "print ('Lib imported successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10222, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features, train_labels, valid_features, valid_labels, test_features, test_labels, label_dict = helper.get_train_cv_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9107, 64, 64, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9107, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, 64, 64, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1012, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(103, 64, 64, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(103, 120)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'affenpinscher': 0,\n",
       " 'afghan_hound': 1,\n",
       " 'african_hunting_dog': 2,\n",
       " 'airedale': 3,\n",
       " 'american_staffordshire_terrier': 4,\n",
       " 'appenzeller': 5,\n",
       " 'australian_terrier': 6,\n",
       " 'basenji': 7,\n",
       " 'basset': 8,\n",
       " 'beagle': 9,\n",
       " 'bedlington_terrier': 10,\n",
       " 'bernese_mountain_dog': 11,\n",
       " 'black-and-tan_coonhound': 12,\n",
       " 'blenheim_spaniel': 13,\n",
       " 'bloodhound': 14,\n",
       " 'bluetick': 15,\n",
       " 'border_collie': 16,\n",
       " 'border_terrier': 17,\n",
       " 'borzoi': 18,\n",
       " 'boston_bull': 19,\n",
       " 'bouvier_des_flandres': 20,\n",
       " 'boxer': 21,\n",
       " 'brabancon_griffon': 22,\n",
       " 'briard': 23,\n",
       " 'brittany_spaniel': 24,\n",
       " 'bull_mastiff': 25,\n",
       " 'cairn': 26,\n",
       " 'cardigan': 27,\n",
       " 'chesapeake_bay_retriever': 28,\n",
       " 'chihuahua': 29,\n",
       " 'chow': 30,\n",
       " 'clumber': 31,\n",
       " 'cocker_spaniel': 32,\n",
       " 'collie': 33,\n",
       " 'curly-coated_retriever': 34,\n",
       " 'dandie_dinmont': 35,\n",
       " 'dhole': 36,\n",
       " 'dingo': 37,\n",
       " 'doberman': 38,\n",
       " 'english_foxhound': 39,\n",
       " 'english_setter': 40,\n",
       " 'english_springer': 41,\n",
       " 'entlebucher': 42,\n",
       " 'eskimo_dog': 43,\n",
       " 'flat-coated_retriever': 44,\n",
       " 'french_bulldog': 45,\n",
       " 'german_shepherd': 46,\n",
       " 'german_short-haired_pointer': 47,\n",
       " 'giant_schnauzer': 48,\n",
       " 'golden_retriever': 49,\n",
       " 'gordon_setter': 50,\n",
       " 'great_dane': 51,\n",
       " 'great_pyrenees': 52,\n",
       " 'greater_swiss_mountain_dog': 53,\n",
       " 'groenendael': 54,\n",
       " 'ibizan_hound': 55,\n",
       " 'irish_setter': 56,\n",
       " 'irish_terrier': 57,\n",
       " 'irish_water_spaniel': 58,\n",
       " 'irish_wolfhound': 59,\n",
       " 'italian_greyhound': 60,\n",
       " 'japanese_spaniel': 61,\n",
       " 'keeshond': 62,\n",
       " 'kelpie': 63,\n",
       " 'kerry_blue_terrier': 64,\n",
       " 'komondor': 65,\n",
       " 'kuvasz': 66,\n",
       " 'labrador_retriever': 67,\n",
       " 'lakeland_terrier': 68,\n",
       " 'leonberg': 69,\n",
       " 'lhasa': 70,\n",
       " 'malamute': 71,\n",
       " 'malinois': 72,\n",
       " 'maltese_dog': 73,\n",
       " 'mexican_hairless': 74,\n",
       " 'miniature_pinscher': 75,\n",
       " 'miniature_poodle': 76,\n",
       " 'miniature_schnauzer': 77,\n",
       " 'newfoundland': 78,\n",
       " 'norfolk_terrier': 79,\n",
       " 'norwegian_elkhound': 80,\n",
       " 'norwich_terrier': 81,\n",
       " 'old_english_sheepdog': 82,\n",
       " 'otterhound': 83,\n",
       " 'papillon': 84,\n",
       " 'pekinese': 85,\n",
       " 'pembroke': 86,\n",
       " 'pomeranian': 87,\n",
       " 'pug': 88,\n",
       " 'redbone': 89,\n",
       " 'rhodesian_ridgeback': 90,\n",
       " 'rottweiler': 91,\n",
       " 'saint_bernard': 92,\n",
       " 'saluki': 93,\n",
       " 'samoyed': 94,\n",
       " 'schipperke': 95,\n",
       " 'scotch_terrier': 96,\n",
       " 'scottish_deerhound': 97,\n",
       " 'sealyham_terrier': 98,\n",
       " 'shetland_sheepdog': 99,\n",
       " 'shih-tzu': 100,\n",
       " 'siberian_husky': 101,\n",
       " 'silky_terrier': 102,\n",
       " 'soft-coated_wheaten_terrier': 103,\n",
       " 'staffordshire_bullterrier': 104,\n",
       " 'standard_poodle': 105,\n",
       " 'standard_schnauzer': 106,\n",
       " 'sussex_spaniel': 107,\n",
       " 'tibetan_mastiff': 108,\n",
       " 'tibetan_terrier': 109,\n",
       " 'toy_poodle': 110,\n",
       " 'toy_terrier': 111,\n",
       " 'vizsla': 112,\n",
       " 'walker_hound': 113,\n",
       " 'weimaraner': 114,\n",
       " 'welsh_springer_spaniel': 115,\n",
       " 'west_highland_white_terrier': 116,\n",
       " 'whippet': 117,\n",
       " 'wire-haired_fox_terrier': 118,\n",
       " 'yorkshire_terrier': 119}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_features.shape, train_labels.shape, valid_features.shape, valid_labels.shape, test_features.shape, test_labels.shape, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CNN Model\n",
    "def conv_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list(conv_ksize + (dimension[-1],) + (conv_num_outputs,))\n",
    "    #print(shape)\n",
    "    filter_weights = tf.Variable(tf.truncated_normal(shape,0,0.1)) # (height, width, input_depth, output_depth)\n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    padding = 'SAME'\n",
    "    #print(list((1,)+conv_strides+(1,)))\n",
    "    #print(filter_weights)\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, filter_weights, list((1,)+conv_strides+(1,)), padding)\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, filter_bias)\n",
    "    \n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    conv_layer = tf.nn.max_pool(\n",
    "        conv_layer,\n",
    "        ksize=[1] + list(pool_ksize) + [1],\n",
    "        strides=[1] + list(pool_strides) + [1],\n",
    "        padding='SAME')\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "def flatten_image(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    dimension = x_tensor.get_shape().as_list()  \n",
    "    print(dimension)\n",
    "    x =  tf.reshape(x_tensor,[-1,prod(dimension[1:])])\n",
    "    print(x.get_shape().as_list())\n",
    "    return x\n",
    "\n",
    "def fully_connected(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list( (dimension[-1],) + (num_outputs,))\n",
    "    print(x_tensor.get_shape())\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor,weight), bias))\n",
    "\n",
    "\n",
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dimension = x_tensor.get_shape().as_list()\n",
    "    shape = list( (dimension[-1],) + (num_outputs,))\n",
    "    print(shape)\n",
    "    weight = tf.Variable(tf.truncated_normal(shape,0,0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "\n",
    "    return tf.add(tf.matmul(x_tensor,weight), bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor model that represents logits.\n",
    "    \"\"\"\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    model = conv_maxpool(x, conv_num_outputs=36, conv_ksize=(4,4), conv_strides=(1,1), pool_ksize=(2,2), pool_strides=(1,1))\n",
    "    model = tf.nn.dropout(model, keep_prob)    \n",
    "\n",
    "    model = flatten_image(model)\n",
    "    #    Play around with different number of outputs\n",
    "    model = fully_connected(model,20)\n",
    "    \n",
    "    model = tf.nn.dropout(model, keep_prob)\n",
    "    \n",
    "    #    Set this to the number of classes\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    model = output(model,labels_count)\n",
    "    return model\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "def cnn_model():\n",
    "    \"\"\"\n",
    "    return: features, labels, keep_prob, logits, cost, accuracy, optimizer of \n",
    "              convolutinal neural network model\n",
    "    \"\"\"\n",
    "    # Remove previous weights, bias, inputs, etc..\n",
    "    tf.reset_default_graph()\n",
    "    # Inputs\n",
    "    image_shape = (SIZE,SIZE,CHANNEL)\n",
    "    features = tf.placeholder(tf.float32, [None] + list(image_shape), name=\"features\")\n",
    "    labels = tf.placeholder(tf.float32, (None, labels_count), name=\"label\")\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_probability\")\n",
    "\n",
    "    # Model\n",
    "    logits = convolutional_net(features, keep_prob)\n",
    "\n",
    "    # Name logits Tensor, so that is can be loaded from disk after training\n",
    "    logits = tf.identity(logits, name='logits')\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    \n",
    "    return features, labels, keep_prob, logits, cost, accuracy, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_stats(session, feature_batch, label_batch, cost, accuracy, features, labels, keep_prob):\n",
    "    \"\"\"\n",
    "    show information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    : features: placeholder for features\n",
    "    : labels: placeholder for labels\n",
    "    : keel_prob: placeholder for keep_probability\n",
    "    \"\"\"\n",
    "    #features, labels, keep_prob, logits, cost, accuracy, optimizer = cnn_model()\n",
    "    loss = session.run(cost, feed_dict={features:feature_batch, labels:label_batch, keep_prob:1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "                features: valid_features,\n",
    "                labels: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                loss,\n",
    "                valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    validation_accuracy = 0.0\n",
    "    log_batch_step = 10\n",
    "    batches = []\n",
    "    loss_batch = []\n",
    "    train_acc_batch = []\n",
    "    valid_acc_batch = []\n",
    "    \n",
    "    features, labels, keep_prob, logits, cost, accuracy, optimizer = cnn_model()\n",
    "\n",
    "    # Feed dicts for training, validation\n",
    "    train_feed_dict = {features: train_features, labels: train_labels, keep_prob:keep_probability}\n",
    "    valid_feed_dict = {features: valid_features, labels: valid_labels, keep_prob:keep_probability}\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "        # Initializing the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "        # Training cycle\n",
    "        for epoch_i in range(epochs):\n",
    "            avg_cost = 0\n",
    "            # Progress bar\n",
    "            batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "            # display((batch_count))\n",
    "            # The training cycle\n",
    "            for batch_i in batches_pbar:\n",
    "                # Get a batch of training features and labels\n",
    "                batch_start = batch_i*batch_size\n",
    "                batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "                batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "                # Run optimizer and get loss\n",
    "                _, l = sess.run(\n",
    "                        [optimizer, cost],\n",
    "                        feed_dict={features: batch_features, labels: batch_labels, keep_prob: keep_probability})\n",
    "                show_stats(sess, batch_features, batch_labels, \n",
    "                            cost, accuracy, features, labels, keep_prob)\n",
    "                  \n",
    "                avg_cost += l / batch_size\n",
    "                        \n",
    "                # Log every 50 batches\n",
    "                if not batch_i % log_batch_step:\n",
    "                    # Calculate Training and Validation accuracy\n",
    "                    training_accuracy = sess.run(accuracy, feed_dict=train_feed_dict)\n",
    "                    validation_accuracy = sess.run(accuracy, feed_dict=valid_feed_dict)\n",
    "                    # Log batches\n",
    "                    previous_batch = batches[-1] if batches else 0\n",
    "                    batches.append(log_batch_step + previous_batch)\n",
    "                    loss_batch.append(l)\n",
    "                    train_acc_batch.append(training_accuracy)\n",
    "                    valid_acc_batch.append(validation_accuracy)\n",
    "            print (\"Epoch:\", (epoch_i+1), \"cost =\", \"{:.5f}\".format(avg_cost))\n",
    "            # Check accuracy against Validation data\n",
    "            validation_accuracy = sess.run(accuracy, feed_dict=valid_feed_dict)\n",
    "            print('Validation accuracy at {}'.format(validation_accuracy))\n",
    "\n",
    "        # Save Model\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, save_model_path)\n",
    "\n",
    "    # plot the cost and validation accuracy\n",
    "    loss_plot = plt.subplot(211)\n",
    "    loss_plot.set_title('Loss')\n",
    "    loss_plot.plot(batches, loss_batch, 'g')\n",
    "    loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "    acc_plot = plt.subplot(212)\n",
    "    acc_plot.set_title('Accuracy')\n",
    "    acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "    acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "    acc_plot.set_ylim([0, 1.0])\n",
    "    acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "    acc_plot.legend(loc=4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 64, 64, 36]\n",
      "[None, 147456]\n",
      "(?, 147456)\n",
      "[20, 120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3:   0%|                                   | 0/5 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7873 Validation Accuracy: 0.008893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3:  20%|█████▏                    | 1/5 [04:10<16:42, 250.56s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7873 Validation Accuracy: 0.003953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3:  40%|██████████▍               | 2/5 [05:31<08:16, 165.64s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7872 Validation Accuracy: 0.004941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3:  60%|███████████████▌          | 3/5 [06:50<04:33, 136.72s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7872 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3:  80%|████████████████████▊     | 4/5 [08:04<02:01, 121.23s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7871 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  1/3: 100%|██████████████████████████| 5/5 [08:38<00:00, 103.64s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 0.01169\n",
      "Validation accuracy at 0.011857707053422928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3:   0%|                                   | 0/5 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7868 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3:  20%|█████▏                    | 1/5 [04:21<17:24, 261.25s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7869 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3:  40%|██████████▍               | 2/5 [05:36<08:24, 168.15s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7868 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3:  60%|███████████████▌          | 3/5 [06:55<04:36, 138.49s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7868 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3:  80%|████████████████████▊     | 4/5 [08:13<02:03, 123.44s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7865 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  2/3: 100%|██████████████████████████| 5/5 [08:47<00:00, 105.41s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 cost = 0.01169\n",
      "Validation accuracy at 0.011857707053422928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3:   0%|                                   | 0/5 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7864 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3:  20%|█████▏                    | 1/5 [05:32<22:10, 332.54s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7865 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3:  40%|██████████▍               | 2/5 [06:39<09:59, 199.71s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7865 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3:  60%|███████████████▌          | 3/5 [07:56<05:17, 158.96s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7864 Validation Accuracy: 0.011858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3:  80%|████████████████████▊     | 4/5 [09:12<02:18, 138.00s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:     4.7859 Validation Accuracy: 0.007905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  3/3: 100%|██████████████████████████| 5/5 [09:42<00:00, 116.52s/batches]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 cost = 0.01169\n",
      "Validation accuracy at 0.007905138656497002\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJP0/uAK2p0FR6kYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a42f624dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('features:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('label:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_probability:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        test_accuracy = sess.run(loaded_acc, feed_dict={loaded_x: test_features, loaded_y: test_labels, loaded_keep_prob: 1.0})\n",
    "        \n",
    "        print('Test Accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dog_breed_recognition\n",
      "Test Accuracy is 0.009708737954497337\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                | 0/10357 [00:00<?, ?it/s]\n",
      "  0%|                                      | 1/10357 [00:00<1:52:25,  1.54it/s]\n",
      "  0%|                                        | 3/10357 [00:00<46:35,  3.70it/s]\n",
      "  0%|                                        | 4/10357 [00:00<40:42,  4.24it/s]\n",
      "  0%|                                        | 5/10357 [00:01<38:06,  4.53it/s]\n",
      "  0%|                                        | 7/10357 [00:01<33:04,  5.22it/s]\n",
      "  0%|                                        | 8/10357 [00:01<31:49,  5.42it/s]\n",
      "  0%|                                       | 10/10357 [00:01<28:53,  5.97it/s]\n",
      "  0%|                                       | 12/10357 [00:01<28:36,  6.03it/s]\n",
      "  0%|                                       | 13/10357 [00:02<27:59,  6.16it/s]\n",
      "  0%|                                       | 15/10357 [00:02<25:39,  6.72it/s]\n",
      "  0%|                                       | 17/10357 [00:02<23:54,  7.21it/s]\n",
      "  0%|                                       | 19/10357 [00:02<22:20,  7.71it/s]\n",
      "  0%|                                       | 23/10357 [00:02<20:04,  8.58it/s]\n",
      "  0%|                                       | 25/10357 [00:02<19:10,  8.98it/s]\n",
      "  0%|                                       | 27/10357 [00:02<18:23,  9.36it/s]\n",
      "  0%|                                       | 29/10357 [00:03<17:48,  9.66it/s]\n",
      "  0%|                                       | 31/10357 [00:03<18:28,  9.31it/s]\n",
      "  0%|▏                                      | 34/10357 [00:03<17:23,  9.89it/s]\n",
      "  0%|▏                                      | 36/10357 [00:03<18:39,  9.22it/s]Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Software\\Software\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Software\\Software\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"D:\\Software\\Software\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      " 11%|████                                 | 1122/10357 [01:13<10:02, 15.33it/s]"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imresize, imread\n",
    "df_test = pd.read_csv('./data/sample_submission.csv')\n",
    "NUMBER_TEST = len(df_test)\n",
    "X_test = np.zeros((NUMBER_TEST, SIZE, SIZE, 3), dtype=np.uint8)\n",
    "for i in tqdm(range(NUMBER_TEST)):\n",
    "    X_test[i] = imresize(imread('./data/test/%s.jpg' % df_test['id'][i]), (SIZE, SIZE)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/labels.csv')\n",
    "df.head()\n",
    "\n",
    "n = len(df)\n",
    "breed = set(df['breed'])\n",
    "n_class = len(breed)\n",
    "class_to_num = dict(zip(breed, range(n_class)))\n",
    "num_to_class = dict(zip(range(n_class), breed))\n",
    "display(class_to_num, n_class, breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_image(classification):\n",
    "    # test ramdom image\n",
    "    loaded_graph = tf.Graph()\n",
    "    top_n_predictions = 120\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as session:\n",
    "    # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(session, save_model_path)\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('features:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('label:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_probability:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "    #    loaded_GDoptimizer = loaded_graph.get_tensor_by_name('GDoptimizer:0')    \n",
    "        #with open(\"data/submission.csv\", 'w',newline='') as csvFile:\n",
    "        #        writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
    "        #        writer.writerow([\"ImageId\",\"Label\"])\n",
    "        \n",
    "        #classification = session.run(tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions), feed_dict={loaded_x: [data], loaded_keep_prob: 1.0})\n",
    "        for i in range(len(X_test)):\n",
    "            data = (X_test[i] - (255 / 2.0)) / 255\n",
    "            classification[i] = session.run(tf.nn.softmax(loaded_logits), feed_dict={loaded_x: [data], loaded_keep_prob: 1.0})\n",
    "\n",
    "            #plt.imshow(img.reshape(IMAGE_SIZE, IMAGE_SIZE), cmap=plt.cm.binary)\n",
    "            #plt.show()\n",
    "       # print ('Top {} prediction :' .format(top_n_predictions))\n",
    "       # print ('{}% ' .format(classification[0]) )\n",
    "       # print ('predicted value {}' .format(classification[1]))\n",
    "        #label = classification[1]\n",
    "        #    with open(\"mnist/submission.csv\", 'a', newline='') as csvFile:\n",
    "        #        writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
    "        #        writer.writerow([num , label[0][0]])\n",
    "            \n",
    "        return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.zeros((len(X_test), len(breed)), dtype=np.float)\n",
    "#print((X_test[0] - (255 / 2.0)) / 255)\n",
    "predict = predict_image(predict)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for b in breed:\n",
    "    df_test[b] = predict[:,label_dict[b]]\n",
    "df_test.to_csv('submission.csv', index=None)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
