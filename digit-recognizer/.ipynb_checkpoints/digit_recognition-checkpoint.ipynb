{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "You can use ** Keras ** to implement your model. Read more at [keras.io](https://keras.io/).\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0)). You are not expected to model your architecture precisely using this model nor get the same performance levels, but this is more to show an exampe of an approach used to solve this particular problem. We encourage you to try out different architectures for yourself and see what works best for you. Here is a useful [forum post](https://discussions.udacity.com/t/goodfellow-et-al-2013-architecture/202363) discussing the architecture as described in the paper and here is [another one](https://discussions.udacity.com/t/what-loss-function-to-use-for-multi-digit-svhn-training/176897) discussing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import all the modules\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imsave\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "WORK_DIRECTORY = 'mnist'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading train-images-idx3-ubyte.gz\n",
      "downloading train-labels-idx1-ubyte.gz\n",
      "downloading t10k-images-idx3-ubyte.gz\n",
      "downloading t10k-labels-idx1-ubyte.gz\n",
      "Extracting mnist\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       ..., \n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features and labels uncompressed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def maybe_download(filename):\n",
    "  print('downloading',filename)\n",
    "  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "  if not tf.gfile.Exists(WORK_DIRECTORY):\n",
    "    tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
    "    print('...')\n",
    "  filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "  if not tf.gfile.Exists(filepath):\n",
    "    filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "    with tf.gfile.GFile(filepath) as f:\n",
    "      size = f.Size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    # Load image data as 1 dimensional array\n",
    "    data = np.array(data, dtype=np.float32).flatten()\n",
    "    data = data.reshape(num_images,IMAGE_SIZE*IMAGE_SIZE*1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    labels = labels.reshape(num_images,1)\n",
    "  return labels\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into np arrays.\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "#train_data = np.array(train_data, dtype=np.float32).flatten()\n",
    "display(train_data.shape)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "display(train_labels.shape)\n",
    "# Limit the amount of data to work with a docker container\n",
    "#docker_size_limit = 60000\n",
    "#train_features, train_labels = resample(train_data, train_labels, n_samples=docker_size_limit)\n",
    "\n",
    "\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "#test_data = np.array(test_data, dtype=np.float32).flatten()\n",
    "\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "\n",
    "display(test_data[0:])\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-data saving done\n",
      "test-data saving done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"mnist/train-images\"):\n",
    "   os.makedirs(\"mnist/train-images\")\n",
    "\n",
    "if not os.path.isdir(\"mnist/test-images\"):\n",
    "   os.makedirs(\"mnist/test-images\")\n",
    "\n",
    "# process train data\n",
    "with open(\"mnist/train-labels.csv\", 'w') as csvFile:\n",
    "  writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
    "  for i in range(len(train_data)):\n",
    "    imsave(\"mnist/train-images/\" + str(i) + \".jpg\", train_data[i][:,:,0])\n",
    "    writer.writerow([\"train-images/\" + str(i) + \".jpg\", train_labels[i]])\n",
    "print('training-data saving done')\n",
    "# repeat for test data\n",
    "with open(\"mnist/test-labels.csv\", 'w') as csvFile:\n",
    "  writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
    "  for i in range(len(test_data)):\n",
    "    imsave(\"mnist/test-images/\" + str(i) + \".jpg\", test_data[i][:,:,0])\n",
    "    writer.writerow([\"test-images/\" + str(i) + \".jpg\", test_labels[i]])\n",
    "print('test-data saving done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [2],\n",
       "       [1],\n",
       "       ..., \n",
       "       [4],\n",
       "       [5],\n",
       "       [6]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data[1][15])\n",
    "display(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Encode the label \n",
    "def label_encoding(x):\n",
    "\n",
    "    # TODO: Implement Function\n",
    "    y = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        y[i,x[i]] = 1\n",
    "    return y\n",
    "\n",
    "train_label_encoded = label_encoding(train_labels)\n",
    "test_label_encoded = label_encoding(test_labels)\n",
    "display(test_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       ..., \n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features and labels randomized and split.\n"
     ]
    }
   ],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(\n",
    "    train_data,\n",
    "    train_label_encoded,\n",
    "    test_size=0.05,\n",
    "    random_state=0)\n",
    "display(train_features)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to build a simple neural network using TensorFlow. Here, your network will be just an input layer and an output layer.\n",
    "\n",
    "\n",
    "For the input here the images have been flattened into a vector of  28×28=784  features. Then, we're trying to predict the image digit so there are 10 output units, one for each label. \n",
    "For the neural network to train on your data, we need the following float32 tensors:\n",
    "\n",
    "features: \n",
    "Placeholder tensor for feature data (train_features/valid_features/test_features)\n",
    "\n",
    "labels: \n",
    "Placeholder tensor for label data (train_labels/valid_labels/test_labels)\n",
    "\n",
    "weights: \n",
    "Variable Tensor with random numbers from a truncated normal distribution.\n",
    "\n",
    "biases: \n",
    "Variable Tensor with all zeros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn infra is done\n"
     ]
    }
   ],
   "source": [
    "# Network Parameters\n",
    "# All the pixels in the image (28 * 28 = 784)\n",
    "features_count = 784 # MNIST data input (img shape: 28*28)\n",
    "# All the labels\n",
    "labels_count = 10 # MNIST total classes (0-9 digits)\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "\n",
    "# multilayer_perceptron\n",
    "#learning_rate = 0.0001\n",
    "\n",
    "# singlelayer_perceptron\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32, name=\"features\")\n",
    "labels = tf.placeholder(tf.float32, name=\"label\")\n",
    "\n",
    "def singlelayer_perceptron(x):\n",
    "    # TODO: Set the weights and biases tensors\n",
    "    weights = tf.Variable(tf.truncated_normal((features_count, labels_count)))\n",
    "    biases = tf.Variable(tf.zeros(labels_count))\n",
    "    \n",
    "    out_layer = tf.matmul(x, weights) + biases\n",
    "    return out_layer\n",
    "    \n",
    "def multilayer_perceptron(x):\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([features_count, n_hidden_1])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, labels_count]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([labels_count]))\n",
    "    }\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Linear Function WX + b\n",
    "#logits = tf.matmul(features, weights) + biases\n",
    "logits = singlelayer_perceptron(features)\n",
    "\n",
    "# multilayer perception model\n",
    "#logits = multilayer_perceptron(features)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "display (logits.shape)\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy\n",
    "cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "# Training loss\n",
    "#loss = tf.reduce_mean(cross_entropy)\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=labels))\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "#init = tf.global_variables_initializer()\n",
    "\n",
    "# Test Cases\n",
    "#with tf.Session() as session:\n",
    "#    session.run(init)\n",
    "#    session.run(loss, feed_dict=train_feed_dict)\n",
    "#    session.run(loss, feed_dict=valid_feed_dict)\n",
    "#    session.run(loss, feed_dict=test_feed_dict)\n",
    "#    biases_data = session.run(biases)\n",
    "#    print (\"predictions\", prediction.eval(feed_dict=test_feed_dict, session=session))\n",
    "#    print(\"test_feature\", test_data)\n",
    "#    print (\"Lable\", test_label_encoded)\n",
    "\n",
    "print('nn infra is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy function created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Determine if the predictions are correct\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32),name='accuracy')\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,name='GDoptimizer')    \n",
    "\n",
    "print('Accuracy function created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|█████████████████████| 570/570 [00:04<00:00, 137.59batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 19.19994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2/10: 100%|█████████████████████| 570/570 [00:04<00:00, 138.86batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 cost = 7.87378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3/10: 100%|█████████████████████| 570/570 [00:04<00:00, 138.49batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 cost = 5.96393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4/10: 100%|█████████████████████| 570/570 [00:04<00:00, 138.68batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 cost = 5.08554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5/10: 100%|█████████████████████| 570/570 [00:04<00:00, 139.03batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 cost = 4.56110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6/10: 100%|█████████████████████| 570/570 [00:04<00:00, 136.04batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 cost = 4.20161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7/10: 100%|█████████████████████| 570/570 [00:04<00:00, 133.94batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 cost = 3.93453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8/10: 100%|█████████████████████| 570/570 [00:04<00:00, 139.53batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 cost = 3.72556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9/10: 100%|█████████████████████| 570/570 [00:04<00:00, 138.98batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 cost = 3.55611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|█████████████████████| 570/570 [00:04<00:00, 137.60batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 cost = 3.41505\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nap4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12802256908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at 0.8679999709129333\n"
     ]
    }
   ],
   "source": [
    "# Change if you have memory restrictions\n",
    "batch_size = 100\n",
    "\n",
    "# TODO: Find the best parameters for each configuration\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "save_model_path = './digit_classification'\n",
    "\n",
    "# Feed dicts for training, validation, and test session\n",
    "train_feed_dict = {features: train_features, labels: train_labels}\n",
    "valid_feed_dict = {features: valid_features, labels: valid_labels}\n",
    "test_feed_dict = {features: test_data, labels: test_label_encoded}\n",
    "\n",
    "\n",
    "# The accuracy measured against the validation set\n",
    "validation_accuracy = 0.0\n",
    "\n",
    "# Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "# Create an operation that initializes all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        avg_cost = 0  \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "       # display((batch_count))\n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = session.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "            \n",
    "            avg_cost += l / batch_size\n",
    "                        \n",
    "            \n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "                #display(training_accuracy,)\n",
    "\n",
    "        print (\"Epoch:\", (epoch_i+1), \"cost =\", \"{:.5f}\".format(avg_cost))\n",
    "        # Check accuracy against Validation data\n",
    "        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(session, save_model_path)\n",
    "\n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Validation accuracy at {}'.format(validation_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:\n",
    "\n",
    "Test the model against hold out dataset/testing data. This will give you a good indicator of how well the model will do in the real world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|█████████████████████| 570/570 [00:01<00:00, 408.28batches/s]\n",
      "Epoch  2/10: 100%|█████████████████████| 570/570 [00:01<00:00, 399.32batches/s]\n",
      "Epoch  3/10: 100%|█████████████████████| 570/570 [00:01<00:00, 396.88batches/s]\n",
      "Epoch  4/10: 100%|█████████████████████| 570/570 [00:01<00:00, 410.35batches/s]\n",
      "Epoch  5/10: 100%|█████████████████████| 570/570 [00:01<00:00, 410.41batches/s]\n",
      "Epoch  6/10: 100%|█████████████████████| 570/570 [00:01<00:00, 373.91batches/s]\n",
      "Epoch  7/10: 100%|█████████████████████| 570/570 [00:01<00:00, 377.64batches/s]\n",
      "Epoch  8/10: 100%|█████████████████████| 570/570 [00:01<00:00, 378.02batches/s]\n",
      "Epoch  9/10: 100%|█████████████████████| 570/570 [00:01<00:00, 399.53batches/s]\n",
      "Epoch 10/10: 100%|█████████████████████| 570/570 [00:01<00:00, 397.56batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 0.8646491169929504\n",
      "Nice Job! Test Accuracy is 0.8664000034332275\n",
      "num: 8553\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADt9JREFUeJzt3X+sVPWZx/HPI2sludQIer0QetnL\nVl3WmGg3IzGyWdGNVVYTvX9oilFp1F5iSrKNDYEQFdSYENnSJbqW0BULYv2RVFb8tSsSI9tEK6Mx\nSGWxau62FwhcoEaqkgZ59o97aC545zvDzJk5w33er4TMzHnmzPfJwIczM+fH19xdAOI5pegGABSD\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOqvWjnYWWed5T09Pa0cEgilv79f+/bts1qe21D4\nzexqSSskjZH0H+6+NPX8np4elcvlRoYEkFAqlWp+bt0f+81sjKR/lzRL0vmSZpvZ+fW+HoDWauQ7\n/3RJH7n7J+7+Z0lPS7oun7YANFsj4Z8s6Q/DHg9ky45hZn1mVjaz8uDgYAPDAchTI+Ef6UeFr50f\n7O6r3L3k7qXOzs4GhgOQp0bCPyCpe9jjb0na1Vg7AFqlkfBvkXSumU01s29I+p6kDfm0BaDZ6t7V\n5+6HzWyepP/W0K6+1e7+29w6A9BUDe3nd/eXJb2cUy8AWojDe4GgCD8QFOEHgiL8QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqVT\ndKM5FixYULH20EMPJde99957k/X77ruvrp7ysG7dumT9lltuqfu1q70v8+fPr/u1TxZs+YGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gqIb285tZv6SDkr6SdNjdS3k0hWO98MILyfqyZcvqfu21a9cm6x0d\nHXW/tiTt27evYm3FihXJdQ8fPtzQ2KeddlrF2vTp0xt67dEgj4N8Lnf3yn/DANoSH/uBoBoNv0t6\n1czeMbO+PBoC0BqNfuyf4e67zOxsSRvN7H/dffPwJ2T/KfRJ0pQpUxocDkBeGtryu/uu7HavpPWS\nvvYriruvcveSu5c6OzsbGQ5AjuoOv5l1mNk3j96X9F1J2/JqDEBzNfKxv0vSejM7+jq/dPf/yqUr\nAE1Xd/jd/RNJF+bYS1jVzh1/5JFHknV3r3vs/v7+ZD11rYCijR07NllPHR9x2WWX5d3OSYddfUBQ\nhB8IivADQRF+ICjCDwRF+IGguHR3C3z44YfJ+hNPPJGsHzp0qO6xe3t7615XktavX5+sz5o1K1nv\n6empe+xqvZdK6TPIx48fX/fYEbDlB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg2M+fg2r78a+66qpk\nfc+ePQ2Nf/nll1esPf300w299v79+5P1avvSq512i+Kw5QeCIvxAUIQfCIrwA0ERfiAowg8ERfiB\noNjPn4Nql9audnnsarq7u5P1u+66q2Lt2WefTa67adOmZH3nzp3JerWprqdNm1axNmPGjOS6U6dO\nTdbRGLb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU1f38ZrZa0rWS9rr7BdmyCZKekdQjqV/Sje7+\nx+a1WbxFixZVrK1cubKpY3/66afJ+p133lmxNjAwkHc7x9i4cWPd606cODFZnzt3brK+ZMmSusdG\nbVv+X0i6+rhlCyVtcvdzJW3KHgM4iVQNv7tvlnTguMXXSVqT3V8j6fqc+wLQZPV+5+9y992SlN2e\nnV9LAFqh6T/4mVmfmZXNrDw4ONjs4QDUqN7w7zGzSZKU3e6t9ER3X+XuJXcvdXZ21jkcgLzVG/4N\nkuZk9+dIej6fdgC0StXwm9lTkt6U9LdmNmBmt0taKulKM/udpCuzxwBOIubuLRusVCp5uVxu2Xh5\nOvPMMyvWDhw4fmdIvqrtD7/55psr1m699da82znGk08+mayvW7euYq3atQJOPfXUZP2SSy5J1jdv\n3pysj0alUknlctlqeS5H+AFBEX4gKMIPBEX4gaAIPxAU4QeC4tLdmfvvvz9Z/+yzz+p+7cmTJyfr\nN910U7Le19eXrJ9zzjkn3FNeli5NH+LR29tbsbZgwYLkum+88Uay/tZbbyXrDzzwQMXaPffck1w3\nArb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAUp/RmLrzwwmR969atFWuTJk1Krvv88+lrnVx88cXJ\n+mh16NChZP2GG25I1l988cVkvaOjo2Ltgw8+SK47ZcqUZL1dcUovgKoIPxAU4QeCIvxAUIQfCIrw\nA0ERfiAozufPVNtnfPvtt1esPfjgg8l1o+7Hr2bs2LHJerXz/av9nX3++ecVa8uWLUuu+/DDDyfr\nowFbfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iqup+fjNbLelaSXvd/YJs2RJJP5A0mD1tkbu/3Kwm\nW6G7uztZf/XVV1vUCY4qlUrJ+jXXXJOsv/TSSxVrjz76aHLdSy+9NFmfPXt2sn4yqGXL/wtJV4+w\n/KfuflH256QOPhBR1fC7+2ZJB1rQC4AWauQ7/zwz22pmq81sfG4dAWiJesP/M0nflnSRpN2SflLp\niWbWZ2ZlMysPDg5WehqAFqsr/O6+x92/cvcjkn4uaXriuavcveTupc7Oznr7BJCzusJvZsMvV9sr\naVs+7QBolVp29T0laaaks8xsQNJiSTPN7CJJLqlf0twm9gigCaqG391H2qH5WBN6AY5R7Xz/hQsX\nJuup/fxHjhxJrvvxxx8n66MBR/gBQRF+ICjCDwRF+IGgCD8QFOEHggpz6e4dO3Yk62eccUay3tXV\nlWc7yMG0adOa9trPPPNMsn733Xc3bexWYcsPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GNmv38jz/+\neLJ+xx13JOvnnXdesr5ly5aKtXHjxiXXxcln27bRf30atvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nENSo2c9/2223NbT++PHp6QbHjBnT0OsD7YYtPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXU/v5l1\nS1oraaKkI5JWufsKM5sg6RlJPZL6Jd3o7n9sXqtpEyZMSNYPHDiQrL/55pvJ+r59+yrWuru7k+ui\nOTZs2FB0Cye1Wrb8hyX92N3/TtIlkn5oZudLWihpk7ufK2lT9hjASaJq+N19t7u/m90/KGm7pMmS\nrpO0JnvaGknXN6tJAPk7oe/8ZtYj6TuSfiOpy913S0P/QUg6O+/mADRPzeE3s3GSfiXpR+7+2Qms\n12dmZTMrDw4O1tMjgCaoKfxmdqqGgv+kuz+XLd5jZpOy+iRJe0da191XuXvJ3UudnZ159AwgB1XD\nb2Ym6TFJ2919+bDSBklzsvtzJD2ff3sAmqWWU3pnSLpF0vtm9l62bJGkpZKeNbPbJf1e0g3NabE2\n+/fvT9ZPP/30ZP3gwYPJ+rXXXlux9sorryTXnThxYrJ+yimj93CLL7/8smKt2tfA5cuXJ+uvv/56\nXT3Vore3t2mv3S6qht/dfy3JKpT/Kd92ALTK6N3kAEgi/EBQhB8IivADQRF+ICjCDwQ1ai7dXc1r\nr72WrF9xxRXJ+tatWyvWJk+enFx37ty5yXq1YxDmzZuXrHd1dSXrjdi5c2eyvnLlymQ9ddrtjh07\n6uopD9X24z/33HPJ+mjAlh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgjJ3b9lgpVLJy+Vyy8Y7EW+/\n/XayPnPmzIq11DnraJ6Ojo5kffHixRVr8+fPz7udtlAqlVQulyudgn8MtvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EFSY8/mrmT59erL+xRdftKgToDXY8gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFXD\nb2bdZva6mW03s9+a2b9ky5eY2U4zey/788/NbxdAXmo5yOewpB+7+7tm9k1J75jZxqz2U3f/1+a1\nB6BZqobf3XdL2p3dP2hm2yWlp6gB0PZO6Du/mfVI+o6k32SL5pnZVjNbbWbjK6zTZ2ZlMysPDg42\n1CyA/NQcfjMbJ+lXkn7k7p9J+pmkb0u6SEOfDH4y0nruvsrdS+5e6uzszKFlAHmoKfxmdqqGgv+k\nuz8nSe6+x92/cvcjkn4uKX1mDIC2Usuv/SbpMUnb3X35sOWThj2tV9K2/NsD0Cy1/No/Q9Itkt43\ns/eyZYskzTaziyS5pH5J6XmoAbSVWn7t/7Wkka4D/nL+7QBoFY7wA4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGXu3rrBzAYl/d+wRWdJ2teyBk5Mu/bWrn1J\n9FavPHv7a3ev6Xp5LQ3/1wY3K7t7qbAGEtq1t3btS6K3ehXVGx/7gaAIPxBU0eFfVfD4Ke3aW7v2\nJdFbvQrprdDv/ACKU/SWH0BBCgm/mV1tZjvM7CMzW1hED5WYWb+ZvZ/NPFwuuJfVZrbXzLYNWzbB\nzDaa2e+y2xGnSSuot7aYuTkxs3Sh7127zXjd8o/9ZjZG0oeSrpQ0IGmLpNnu/kFLG6nAzPolldy9\n8H3CZvaPkv4kaa27X5Ate0jSAXdfmv3HOd7dF7RJb0sk/anomZuzCWUmDZ9ZWtL1kr6vAt+7RF83\nqoD3rYgt/3RJH7n7J+7+Z0lPS7qugD7anrtvlnTguMXXSVqT3V+joX88LVeht7bg7rvd/d3s/kFJ\nR2eWLvS9S/RViCLCP1nSH4Y9HlB7Tfntkl41s3fMrK/oZkbQlU2bfnT69LML7ud4VWdubqXjZpZu\nm/eunhmv81ZE+Eea/aeddjnMcPe/lzRL0g+zj7eoTU0zN7fKCDNLt4V6Z7zOWxHhH5DUPezxtyTt\nKqCPEbn7rux2r6T1ar/Zh/ccnSQ1u91bcD9/0U4zN480s7Ta4L1rpxmviwj/FknnmtlUM/uGpO9J\n2lBAH19jZh3ZDzEysw5J31X7zT68QdKc7P4cSc8X2Msx2mXm5kozS6vg967dZrwu5CCfbFfGv0ka\nI2m1uz/Y8iZGYGZ/o6GtvTQ0iekvi+zNzJ6SNFNDZ33tkbRY0n9KelbSFEm/l3SDu7f8h7cKvc3U\n0EfXv8zcfPQ7dot7+wdJ/yPpfUlHssWLNPT9urD3LtHXbBXwvnGEHxAUR/gBQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwjq/wHdvi+sTJv8/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12830466668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN predicted [[ 0.38478211  0.28185791  0.24503116]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7, 3, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.38478211,  0.28185791,  0.24503116]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# The accuracy measured against the test set\n",
    "test_accuracy = 0.0\n",
    "loaded_graph = tf.Graph()\n",
    "save_model_path = './digit_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "with tf.Session() as session:\n",
    "#with tf.Session(graph=loaded_graph) as session:\n",
    "    # Load model\n",
    "#    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "#    loader.restore(session, save_model_path)\n",
    "    # Get Tensors from loaded model\n",
    "#    loaded_x = loaded_graph.get_tensor_by_name('features:0')\n",
    "#    loaded_y = loaded_graph.get_tensor_by_name('label:0')\n",
    "#    loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "#    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "#    loaded_GDoptimizer = loaded_graph.get_tensor_by_name('GDoptimizer:0')      \n",
    "    session.run(init)\n",
    "    batch_count = int(math.ceil(len(train_features)/batch_size))\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        \n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "        \n",
    "        # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*batch_size\n",
    "            batch_features = train_features[batch_start:batch_start + batch_size]\n",
    "            batch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\n",
    "            # Run optimizer\n",
    "            _ = session.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Check accuracy against Test data\n",
    "        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "        training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "    # Print Random Samples\n",
    "#    random_test_features = test_data[10]\n",
    "#    random_test_labels = test_label_encoded[10]\n",
    "#    random_test_predictions = session.run(\n",
    "#            tf.nn.top_k(tf.nn.softmax(logits), top_n_predictions),\n",
    "#            feed_dict={features: random_test_features, labels: random_test_labels})\n",
    "\n",
    "#printf('prdiction {} '.format(random_test_predictions))\n",
    "#printf('actual {}'.format(test_label_encoded))\n",
    "    print('Training Accuracy is {}'.format(training_accuracy))\n",
    "    assert test_accuracy >= 0.80, 'Test accuracy at {}, should be equal to or greater than 0.80'.format(test_accuracy)\n",
    "    print('Nice Job! Test Accuracy is {}'.format(test_accuracy))\n",
    "# test ramdom image\n",
    "    num = randint(0, test_data.shape[0])\n",
    "    print ('num:', num)\n",
    "    img = test_data[num]\n",
    "    classification = session.run(tf.nn.top_k(tf.nn.softmax(logits), top_n_predictions), feed_dict={features: [img]})\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    print ('NN predicted', classification[0])\n",
    "    display (classification.indices, classification.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./digit_classification\n",
      "num: 9177\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12800378b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 prediction :\n",
      "[[  9.99999847e+01   8.57189389e-06   2.03421769e-06]]% \n",
      "predicted value [[3 5 8]]\n"
     ]
    }
   ],
   "source": [
    "# test ramdom image\n",
    "loaded_graph = tf.Graph()\n",
    "save_model_path = './digit_classification'\n",
    "top_n_predictions = 3\n",
    "\n",
    "with tf.Session(graph=loaded_graph) as session:\n",
    "    # Load model\n",
    "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "    loader.restore(session, save_model_path)\n",
    "    # Get Tensors from loaded model\n",
    "    loaded_x = loaded_graph.get_tensor_by_name('features:0')\n",
    "    loaded_y = loaded_graph.get_tensor_by_name('label:0')\n",
    "    loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "#    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "#    loaded_GDoptimizer = loaded_graph.get_tensor_by_name('GDoptimizer:0')      \n",
    "\n",
    "    num = randint(0, test_data.shape[0])\n",
    "    print ('num:', num)\n",
    "    img = test_data[num]\n",
    "    classification = session.run(tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions), feed_dict={loaded_x: [img]})\n",
    "    plt.imshow(img.reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    print ('Top {} prediction :' .format(top_n_predictions))\n",
    "    print ('{}% ' .format(classification[0]*100) )\n",
    "    print ('predicted value {}' .format(classification[1]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
